{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b7e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add5a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/user/Downloads/Ziadoo/FER Dataset/fer2013.csv\")\n",
    "\n",
    "# Filter out rows where 'emotion' column has values 0 or 4\n",
    "filtered_data = data[~data['emotion'].isin([4])]\n",
    "\n",
    "# Define a mapping of old values to new values\n",
    "replacement_mapping = {5: 4, 6: 5}\n",
    "\n",
    "# Replace the 'emotion' column values based on the mapping, using .loc to avoid SettingWithCopyWarning\n",
    "filtered_data.loc[:, 'emotion'] = filtered_data['emotion'].replace(replacement_mapping)\n",
    "\n",
    "# Split the dataset based on the type\n",
    "training_data = filtered_data[filtered_data.iloc[:, 2] == 'Training']\n",
    "public_test_data = filtered_data[filtered_data.iloc[:, 2] == 'PublicTest']\n",
    "private_test_data = filtered_data[filtered_data.iloc[:, 2] == 'PrivateTest']\n",
    "test_data = filtered_data[(filtered_data.iloc[:, 2] == 'PublicTest') | (filtered_data.iloc[:, 2] == 'PrivateTest')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5676cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the pixel data\n",
    "def preprocess_data(data):\n",
    "    # Convert pixels from string to numpy arrays\n",
    "    images = data.iloc[:, 1].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape(48,48))\n",
    "    \n",
    "    # Stack images and expand dimensions to make them compatible with VGG16 (3-channel RGB)\n",
    "    images = np.stack(images, axis=0).reshape(-1, 48, 48, 1)\n",
    "    images = np.repeat(images, 3, axis=3)\n",
    "    \n",
    "    # Normalize the images\n",
    "    images = images / 255.0\n",
    "    \n",
    "    # Convert labels to numpy array\n",
    "    labels = data.iloc[:, 0].values\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Apply preprocessing to each data split\n",
    "train_images, train_labels = preprocess_data(training_data)\n",
    "public_test_images, public_test_labels = preprocess_data(public_test_data)\n",
    "private_test_images, private_test_labels = preprocess_data(private_test_data)\n",
    "test_images, test_labels = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e729804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "train_images = torch.tensor(train_images).permute(0, 3, 1, 2).float().to(device)\n",
    "train_labels = torch.tensor(train_labels).long().to(device)\n",
    "public_test_images = torch.tensor(public_test_images).permute(0, 3, 1, 2).float().to(device)\n",
    "public_test_labels = torch.tensor(public_test_labels).long().to(device)\n",
    "private_test_images = torch.tensor(private_test_images).permute(0, 3, 1, 2).float().to(device)\n",
    "private_test_labels = torch.tensor(private_test_labels).long().to(device)\n",
    "test_images = torch.tensor(test_images).permute(0, 3, 1, 2).float().to(device)\n",
    "test_labels = torch.tensor(test_labels).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b59f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "public_test_dataset = TensorDataset(public_test_images, public_test_labels)\n",
    "private_test_dataset = TensorDataset(private_test_images, private_test_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588773d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32  # You can adjust the batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "public_test_loader = DataLoader(public_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "private_test_loader = DataLoader(private_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570bd735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\envs\\newcuda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\miniconda3\\envs\\newcuda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Modify VGG16\n",
    "vgg16 = models.vgg16(pretrained=False)  # Set to False since we're training from scratch\n",
    "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 6)  # Modify the last layer\n",
    "vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f2d3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, device, epochs):\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer (you can change the learning rate if needed)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "    \n",
    "    # Scheduler for learning rate decay\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = validation_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Training complete')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a78dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "Train Loss: 1.6401 Acc: 0.3008\n",
      "Val Loss: 1.6312 Acc: 0.2986\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "Train Loss: 1.5525 Acc: 0.3487\n",
      "Val Loss: 1.3984 Acc: 0.4338\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "Train Loss: 1.3329 Acc: 0.4665\n",
      "Val Loss: 1.2348 Acc: 0.5142\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "Train Loss: 1.2030 Acc: 0.5224\n",
      "Val Loss: 1.1687 Acc: 0.5389\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "Train Loss: 1.1036 Acc: 0.5730\n",
      "Val Loss: 1.1124 Acc: 0.5833\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "Train Loss: 1.0238 Acc: 0.6036\n",
      "Val Loss: 1.0569 Acc: 0.5905\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "Train Loss: 0.9535 Acc: 0.6323\n",
      "Val Loss: 1.0413 Acc: 0.6022\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "Train Loss: 0.7380 Acc: 0.7256\n",
      "Val Loss: 0.9467 Acc: 0.6495\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "Train Loss: 0.6324 Acc: 0.7684\n",
      "Val Loss: 0.9745 Acc: 0.6579\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "Train Loss: 0.5297 Acc: 0.8083\n",
      "Val Loss: 1.0108 Acc: 0.6642\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "Train Loss: 0.4138 Acc: 0.8563\n",
      "Val Loss: 1.1383 Acc: 0.6671\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "Train Loss: 0.2983 Acc: 0.8997\n",
      "Val Loss: 1.2973 Acc: 0.6487\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "Train Loss: 0.2146 Acc: 0.9303\n",
      "Val Loss: 1.4372 Acc: 0.6445\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "Train Loss: 0.1693 Acc: 0.9438\n",
      "Val Loss: 1.5514 Acc: 0.6671\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "Train Loss: 0.0807 Acc: 0.9786\n",
      "Val Loss: 1.6517 Acc: 0.6746\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "Train Loss: 0.0496 Acc: 0.9881\n",
      "Val Loss: 1.7480 Acc: 0.6767\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "Train Loss: 0.0376 Acc: 0.9917\n",
      "Val Loss: 1.8428 Acc: 0.6788\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "Train Loss: 0.0296 Acc: 0.9937\n",
      "Val Loss: 1.9204 Acc: 0.6784\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "Train Loss: 0.0251 Acc: 0.9951\n",
      "Val Loss: 1.9927 Acc: 0.6759\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "Train Loss: 0.0202 Acc: 0.9964\n",
      "Val Loss: 2.0594 Acc: 0.6755\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "Train Loss: 0.0173 Acc: 0.9969\n",
      "Val Loss: 2.1471 Acc: 0.6755\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "Train Loss: 0.0148 Acc: 0.9974\n",
      "Val Loss: 2.1491 Acc: 0.6759\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "Train Loss: 0.0145 Acc: 0.9979\n",
      "Val Loss: 2.1524 Acc: 0.6771\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "Train Loss: 0.0139 Acc: 0.9975\n",
      "Val Loss: 2.1577 Acc: 0.6767\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "Train Loss: 0.0138 Acc: 0.9972\n",
      "Val Loss: 2.1629 Acc: 0.6767\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "Train Loss: 0.0134 Acc: 0.9977\n",
      "Val Loss: 2.1694 Acc: 0.6767\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "Train Loss: 0.0132 Acc: 0.9979\n",
      "Val Loss: 2.1760 Acc: 0.6759\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "Train Loss: 0.0123 Acc: 0.9981\n",
      "Val Loss: 2.1808 Acc: 0.6771\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "Train Loss: 0.0122 Acc: 0.9980\n",
      "Val Loss: 2.1814 Acc: 0.6767\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "Train Loss: 0.0124 Acc: 0.9980\n",
      "Val Loss: 2.1817 Acc: 0.6767\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "Train Loss: 0.0121 Acc: 0.9982\n",
      "Val Loss: 2.1823 Acc: 0.6763\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "Train Loss: 0.0124 Acc: 0.9978\n",
      "Val Loss: 2.1828 Acc: 0.6763\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "Train Loss: 0.0128 Acc: 0.9980\n",
      "Val Loss: 2.1835 Acc: 0.6763\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "Train Loss: 0.0120 Acc: 0.9984\n",
      "Val Loss: 2.1841 Acc: 0.6767\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "Train Loss: 0.0123 Acc: 0.9980\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "Train Loss: 0.0125 Acc: 0.9979\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "Train Loss: 0.0122 Acc: 0.9980\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "Train Loss: 0.0123 Acc: 0.9982\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "Train Loss: 0.0126 Acc: 0.9980\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "Train Loss: 0.0123 Acc: 0.9981\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "Train Loss: 0.0127 Acc: 0.9977\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "Train Loss: 0.0126 Acc: 0.9978\n",
      "Val Loss: 2.1848 Acc: 0.6767\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "Train Loss: 0.0125 Acc: 0.9980\n",
      "Val Loss: 2.1848 Acc: 0.6767\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "Train Loss: 0.0128 Acc: 0.9980\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "Train Loss: 0.0128 Acc: 0.9980\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "Train Loss: 0.0124 Acc: 0.9979\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "Train Loss: 0.0127 Acc: 0.9979\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "Train Loss: 0.0124 Acc: 0.9981\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "Train Loss: 0.0125 Acc: 0.9979\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "Train Loss: 0.0124 Acc: 0.9979\n",
      "Val Loss: 2.1847 Acc: 0.6767\n",
      "\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Split training data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create DataLoaders for the training and validation sets\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(vgg16, train_loader, val_loader, device, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a958061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5ac368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Public Test Loader\n",
      "Accuracy: 66.83%\n",
      "Confusion Matrix:\n",
      "[[275   9  79  30   6  68]\n",
      " [ 18  24   9   2   0   3]\n",
      " [ 75   4 258  38  25  96]\n",
      " [ 41   0  38 730  19  67]\n",
      " [ 14   1  69  19 296  16]\n",
      " [ 57   2 100  66   3 379]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "print(\"Testing on Public Test Loader\")\n",
    "test_model(trained_model, public_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3d31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on Private Test Loader\n",
      "Accuracy: 65.88%\n",
      "Confusion Matrix:\n",
      "[[265   6 109  38   3  70]\n",
      " [ 14  29   8   2   0   2]\n",
      " [ 84  10 267  36  46  85]\n",
      " [ 38   2  38 712  19  70]\n",
      " [  8   2  80  19 287  20]\n",
      " [ 67   3  78  62   3 413]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting on Private Test Loader\")\n",
    "test_model(trained_model, private_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73835aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on Combined Test Set\n",
      "Accuracy: 66.35%\n",
      "Confusion Matrix:\n",
      "[[ 540   15  188   68    9  138]\n",
      " [  32   53   17    4    0    5]\n",
      " [ 159   14  525   74   71  181]\n",
      " [  79    2   76 1442   38  137]\n",
      " [  22    3  149   38  583   36]\n",
      " [ 124    5  178  128    6  792]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting on Combined Test Set\")\n",
    "test_model(trained_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda 11.8",
   "language": "python",
   "name": "newcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
